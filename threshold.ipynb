{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import lesion\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import unet\n",
    "import residual_unet\n",
    "import utils as util\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import jaccard_score as jsc\n",
    "device = torch.device(\"cuda:0\")\n",
    "import ECE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor_segmap(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, segmap):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        # In this case, Channels is 1, so there is no need to swap since data is in HxW      \n",
    "  \n",
    "        segmap = np.array(segmap)\n",
    "        return torch.from_numpy(segmap) / 255\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "        transforms.RandomGrayscale(1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "seg_transform = ToTensor_segmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "dataset = lesion.LesionDataset(\"data\",folder_name = 'val',joint_transform=False,img_transform=image_transform, seg_transform=seg_transform,verbose = True)\n",
    "loader = DataLoader(dataset, batch_size=batch_size,shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): res_unet_gate(\n",
       "    (MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (drop): GaussianDropout()\n",
       "    (preprocess): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (down1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (down2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (down3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (up1): upblock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (upconv): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (up2): upblock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (upconv): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (up3): upblock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (upconv): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (gate1): gate(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (gate2): gate(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (gate3): gate(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (up4): upblock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (upconv): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (logits): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"gate_gaussian.pth\"\n",
    "model = torch.load(\"models/\" + file_name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dropout(m):\n",
    "    if type(m) == nn.Dropout2d:\n",
    "        m.train()\n",
    "        \n",
    "#T is the number of times to sample to approximate the posterior predictive distribution\n",
    "#Assume model in eval mode\n",
    "def mc(loader,T,batch_size = 2,bayesian = True):\n",
    "    model.eval()\n",
    "    total = batch_size * len(loader)\n",
    "    if(bayesian):\n",
    "        print(\"Bayesian Mode\")\n",
    "        model.apply(apply_dropout)\n",
    "    mean = np.zeros((total, 2, 512, 1024))\n",
    "    var = np.zeros((total, 2, 512, 1024))\n",
    "    targets = np.zeros((total, 512, 1024))\n",
    "    for iteration in range(T):\n",
    "        for i,data in enumerate(loader):\n",
    "                image = data[0].to(device)\n",
    "                m = nn.Softmax2d()\n",
    "                output = model(image)\n",
    "                output = m(output)\n",
    "                output = output.detach().cpu().numpy()\n",
    "                segmap = data[1].numpy()\n",
    "                \n",
    "                mean[batch_size*i:batch_size*i + batch_size] += output\n",
    "                var[batch_size*i:batch_size*i + batch_size] += output**2\n",
    "                if(iteration==0):\n",
    "                    targets[batch_size*i:batch_size*i + batch_size] = segmap\n",
    "    mean = mean / T\n",
    "    var = var / T\n",
    "    var = var - mean**2\n",
    "    return mean,targets,var\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,_,var = mc(loader,1,bayesian=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check, only dropout module should be on training mode for Bayesian\n",
    "for module in model.modules():\n",
    "        if(module.__class__.__name__.startswith('Dropout')):\n",
    "            print(module)\n",
    "            print(module.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511745442758911"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence = mean.max(axis=1)\n",
    "avg_conf = 0\n",
    "for i in range(150):\n",
    "    avg_conf += confidence[i].mean()\n",
    "avg_conf/=150\n",
    "avg_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncert_type = \"conf\"\n",
    "if(uncert_type == \"conf\"):\n",
    "    uncertainty = confidence\n",
    "elif uncert_type ==\"var\":\n",
    "    uncertainty = var.max(axis=1)\n",
    "    \n",
    "avg_uncertainty = 0\n",
    "#150 images in test set\n",
    "for i in range(150):\n",
    "    avg_uncertainty+= uncertainty[i].mean()\n",
    "avg_uncertainty /=150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511745442758911"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_set = lesion.LesionDataset(\"data\",folder_name = 'test',joint_transform=False,img_transform=image_transform, seg_transform=seg_transform,verbose = True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size,shuffle=False, num_workers=4)\n",
    "total = len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,target,var = mc(test_loader,T = 1, bayesian = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mean.argmax(axis=1)# test prediction\n",
    "if(uncert_type == \"conf\"):\n",
    "    cm = mean.max(axis=1)\n",
    "    upper = np.nonzero(cm <= avg_uncertainty)\n",
    "    lower = np.nonzero(cm > avg_uncertainty)\n",
    "elif(uncert_type == \"var\"):\n",
    "    cm = var.max(axis=1) # certainity map, 1 for certain, 0 for uncertain\n",
    "    upper = np.nonzero(cm > avg_uncertainty)\n",
    "    lower = np.nonzero(cm <= avg_uncertainty)\n",
    "cm[upper] = 0\n",
    "cm[lower]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "P(accurate|certain)\n",
    "'''\n",
    "def ac(gt,pred,cm):\n",
    "    #gt = groundtruth, pred = predictions, cm = certainty map\n",
    "    loc = np.nonzero(cm==1) # location of certain pixels\n",
    "    gt = gt[loc]\n",
    "    pred = pred[loc]\n",
    "    p = np.count_nonzero(gt == pred) # number of accurate pixels given they are certain\n",
    "    return p/np.count_nonzero(cm==1)\n",
    "'''\n",
    "p(uncertain|inaccurate)\n",
    "'''\n",
    "def uia(gt,pred,cm):\n",
    "    loc = np.nonzero(gt != pred) # location of inaccurate pixels\n",
    "    cm = cm[loc]\n",
    "    return np.count_nonzero(cm==0)/np.count_nonzero(gt!=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = ac(target,pred,cm) #prob of accurate given certain\n",
    "puia =uia(target,pred,cm) #prob of uncertain given inaccurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob of accurate given certain is:0.9703858750333965 \n",
      "Prob of uncertain given inaccurate is:0.7385511933498639 \n"
     ]
    }
   ],
   "source": [
    "print(\"Prob of accurate given certain is:{} \".format(pac))\n",
    "print(\"Prob of uncertain given inaccurate is:{} \".format(puia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(target[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
